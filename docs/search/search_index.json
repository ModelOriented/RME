{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"RME - Recurrent Memory Explainer Overview Recurrent Memory Explainer (RME) is a tool for creating interpretable explanations, dedicated to models operating on sequential data. RME focuses on the memory of a sequential model and tries to explain the decision by pointing important places in the sequence that had an effect on the prediction. RME is based on so-called \u201ememory profiles\u201d, which are intuitive and can be easily visualised on simple plot charts. Installation RME can be istalled directly from github using pip: pip install git+https://github.com/kobylkam/RME Demo A machine learning model predicting the sentiment of the sentence (whether it is positive or negative) serves as an example of RME demo explanations. Full code of an example can be found in notebooks folder. 1. Creating an explainer At the beginning, we create an explainer and pass the whole dataset to construct a vocabulary. The vocabulary is going to be used to construct perturbations of the instance being explained. from RME import explainer.Explainer e = Explainer(train_set=data) 2. Explaining instance We are interested in explaining the following instance: It is a wonderful World! . We need to pass model's predict_proba function, which outputs classes' probabilities and supply the class we are interested (0 - negative / 1 - positive). e.explain_instance(instance = ['What a wonderful World!'], predict_function = predict_function, class_index=1) We can also calculate step-by-step prediction to see how the prediction changed after each word. e.explain_instance(instance = ['What a wonderful World!'], predict_function = predict_function, class_index=1) 3. Visualization After explaining the instance, the module is ready to visualize obtained results. e.plot_local_perturbations(type='probability_change', title = 'Demo explanation, class: positive') e.plot_local_perturbations(type='probability_change', title = 'Demo explanation, class: positive') e.plot_local_perturbations(type='probability_change', title = 'Demo explanation, class: positive') Once the explainer is constructed, it can serve for various instances. Below, the RME visualizes the impact of the following words on negative sentiment prediction for the sentence: It was the worst and most boring movie I have ever seen . e.explain_instance(instance=['It was the worst movie I have ever seen!'],predict_function=predict_function,class_index=0) e.plot_local_perturbations(type='probability_change', title = 'Demo explanation, class: positive')","title":"Home"},{"location":"#rme-recurrent-memory-explainer","text":"","title":"RME - Recurrent Memory Explainer "},{"location":"#overview","text":"Recurrent Memory Explainer (RME) is a tool for creating interpretable explanations, dedicated to models operating on sequential data. RME focuses on the memory of a sequential model and tries to explain the decision by pointing important places in the sequence that had an effect on the prediction. RME is based on so-called \u201ememory profiles\u201d, which are intuitive and can be easily visualised on simple plot charts.","title":"Overview"},{"location":"#installation","text":"RME can be istalled directly from github using pip: pip install git+https://github.com/kobylkam/RME","title":"Installation"},{"location":"#demo","text":"A machine learning model predicting the sentiment of the sentence (whether it is positive or negative) serves as an example of RME demo explanations. Full code of an example can be found in notebooks folder.","title":"Demo"},{"location":"#1-creating-an-explainer","text":"At the beginning, we create an explainer and pass the whole dataset to construct a vocabulary. The vocabulary is going to be used to construct perturbations of the instance being explained. from RME import explainer.Explainer e = Explainer(train_set=data)","title":"1. Creating an explainer"},{"location":"#2-explaining-instance","text":"We are interested in explaining the following instance: It is a wonderful World! . We need to pass model's predict_proba function, which outputs classes' probabilities and supply the class we are interested (0 - negative / 1 - positive). e.explain_instance(instance = ['What a wonderful World!'], predict_function = predict_function, class_index=1) We can also calculate step-by-step prediction to see how the prediction changed after each word. e.explain_instance(instance = ['What a wonderful World!'], predict_function = predict_function, class_index=1)","title":"2. Explaining instance"},{"location":"#3-visualization","text":"After explaining the instance, the module is ready to visualize obtained results. e.plot_local_perturbations(type='probability_change', title = 'Demo explanation, class: positive') e.plot_local_perturbations(type='probability_change', title = 'Demo explanation, class: positive') e.plot_local_perturbations(type='probability_change', title = 'Demo explanation, class: positive') Once the explainer is constructed, it can serve for various instances. Below, the RME visualizes the impact of the following words on negative sentiment prediction for the sentence: It was the worst and most boring movie I have ever seen . e.explain_instance(instance=['It was the worst movie I have ever seen!'],predict_function=predict_function,class_index=0) e.plot_local_perturbations(type='probability_change', title = 'Demo explanation, class: positive')","title":"3. Visualization"},{"location":"documentation/","text":"RME - documentation This is a documentation of all available functionalities of RME package. The module consist of one class with two explanation methods and three plot methods (so far). Classes Explainer Base class for RME explainer. Each attribute is updated by explain_instance method, except for partial_predictions and initial arguments. Arguments train_set : A train set used to construct the model. This set is used to construct vocabulary . vocabulary : (default None) a set of single time step values used to create perturbations. If not supplied, it is created based on the train_set via extraction of distinct time step values Attributes train_set - initial argument vocabulary - initial argument time_steps - array with time steps of explained instance, updated by explain instance perturbed_probabilities - array with probabilities per each perturbation at each time step probability_change - array with the difference between perturbation probability and base probability of the instance per each perturbation at each time step variances - variance of probability changes per each time step mean_absolute - mean of perturbed_probabilities at each time step mean_change - mean of probability_change at each time step partial_predictions : class predicted after each time step, updated by step_by_step_prediction instance_value : the probability (score) of the explained instance Examples Currently, RME supports recurrent models operating on text data. Example below creates a vocabulary from from RME.explainer import Explainer # First, let's define a train set: Sentences = ['This is a good movie', 'This is a bad book', 'It is a wonderful World!'] # Now, let's pass it to the explainer and check the created vocabulary. e = Explainer(train_set=Sentences) e.vocabulary Methods explain_instance Basic method which produces RME explanations. instance - instance to be explained, e.g.: ['Explain this sentence, please!'] predict_function - model predict probabilities function distance='L1' - distance metric for probability_change computation (valid values: 'L1' , 'L2' ) class_index=0 - class to be explained (default 0) Updates: perturbed_probabilities , probability_change , variances , mean_absolute , mean_change , instance value attributes. step_by_step_prediction Method which prepares partial predictions. instance - instance to be prepared partial predictions predict_function - predict probabilities function that outputs probability per class Updates: partial_predictions attribute. plot_local_perturbations Method for plotting basic RME explanations. type='probabilities' - whether to plot perturbed_probabilities or probability_change show_mean=True - wheter to show average (adjusted) memory profiles or not plot_type='profiles' - either 'profiles' - plot with memory profiles, 'scores' - plot with memory scores as bars or 'none' highlights=None - list of vocabulary values to be highlighted, e.g. ['This','That'] dpi=72 - dots per inch (graphic param) figsize=(8, 6) - figure size (graphic param) title='Step probabilities and mean' - plot title order_time_steps = False - if True, time step values are replaced by ordered numbers (starting from 1) y_lim=None - vertical axis limits: (a,b) Returns : Matplotlib plot. plot_time_step_dispersion Method for plotting memory scores. dispersion_measure='std' - whether to plot memory scores ( std ) or variance of memory profiles ( var ) dpi=72 - dots per inch (graphic param) figsize=(8, 6) - figure size (graphic param) title = 'Variance vs time step' - plot title Returns : Matplotlib plot. plot_partial_predictions Method for plotting partial predictions chart. class_dictionary=None - dicitonary with class names dpi=72 - dots per inch (graphic param) figsize=(8, 6) - figure size (graphic param) title = 'Prediction progress' - plot title Returns : Matplotlib plot.","title":"Documentation"},{"location":"documentation/#rme-documentation","text":"This is a documentation of all available functionalities of RME package. The module consist of one class with two explanation methods and three plot methods (so far).","title":"RME - documentation"},{"location":"documentation/#classes","text":"","title":"Classes"},{"location":"documentation/#explainer","text":"Base class for RME explainer. Each attribute is updated by explain_instance method, except for partial_predictions and initial arguments.","title":"Explainer"},{"location":"documentation/#arguments","text":"train_set : A train set used to construct the model. This set is used to construct vocabulary . vocabulary : (default None) a set of single time step values used to create perturbations. If not supplied, it is created based on the train_set via extraction of distinct time step values","title":"Arguments"},{"location":"documentation/#attributes","text":"train_set - initial argument vocabulary - initial argument time_steps - array with time steps of explained instance, updated by explain instance perturbed_probabilities - array with probabilities per each perturbation at each time step probability_change - array with the difference between perturbation probability and base probability of the instance per each perturbation at each time step variances - variance of probability changes per each time step mean_absolute - mean of perturbed_probabilities at each time step mean_change - mean of probability_change at each time step partial_predictions : class predicted after each time step, updated by step_by_step_prediction instance_value : the probability (score) of the explained instance","title":"Attributes"},{"location":"documentation/#examples","text":"Currently, RME supports recurrent models operating on text data. Example below creates a vocabulary from from RME.explainer import Explainer # First, let's define a train set: Sentences = ['This is a good movie', 'This is a bad book', 'It is a wonderful World!'] # Now, let's pass it to the explainer and check the created vocabulary. e = Explainer(train_set=Sentences) e.vocabulary","title":"Examples"},{"location":"documentation/#methods","text":"","title":"Methods"},{"location":"documentation/#explain_instance","text":"Basic method which produces RME explanations. instance - instance to be explained, e.g.: ['Explain this sentence, please!'] predict_function - model predict probabilities function distance='L1' - distance metric for probability_change computation (valid values: 'L1' , 'L2' ) class_index=0 - class to be explained (default 0) Updates: perturbed_probabilities , probability_change , variances , mean_absolute , mean_change , instance value attributes.","title":"explain_instance"},{"location":"documentation/#step_by_step_prediction","text":"Method which prepares partial predictions. instance - instance to be prepared partial predictions predict_function - predict probabilities function that outputs probability per class Updates: partial_predictions attribute.","title":"step_by_step_prediction"},{"location":"documentation/#plot_local_perturbations","text":"Method for plotting basic RME explanations. type='probabilities' - whether to plot perturbed_probabilities or probability_change show_mean=True - wheter to show average (adjusted) memory profiles or not plot_type='profiles' - either 'profiles' - plot with memory profiles, 'scores' - plot with memory scores as bars or 'none' highlights=None - list of vocabulary values to be highlighted, e.g. ['This','That'] dpi=72 - dots per inch (graphic param) figsize=(8, 6) - figure size (graphic param) title='Step probabilities and mean' - plot title order_time_steps = False - if True, time step values are replaced by ordered numbers (starting from 1) y_lim=None - vertical axis limits: (a,b) Returns : Matplotlib plot.","title":"plot_local_perturbations"},{"location":"documentation/#plot_time_step_dispersion","text":"Method for plotting memory scores. dispersion_measure='std' - whether to plot memory scores ( std ) or variance of memory profiles ( var ) dpi=72 - dots per inch (graphic param) figsize=(8, 6) - figure size (graphic param) title = 'Variance vs time step' - plot title Returns : Matplotlib plot.","title":"plot_time_step_dispersion"},{"location":"documentation/#plot_partial_predictions","text":"Method for plotting partial predictions chart. class_dictionary=None - dicitonary with class names dpi=72 - dots per inch (graphic param) figsize=(8, 6) - figure size (graphic param) title = 'Prediction progress' - plot title Returns : Matplotlib plot.","title":"plot_partial_predictions"}]}