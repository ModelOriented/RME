{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"RME - Recurrent Memory Explainer Overview Recurrent Memory Explainer (RME) is a tool for creating interpretable explanations, dedicated to models operating on sequential data. RME focuses on the memory of a sequential model and tries to explain the decision by pointing important places in the sequence that had an effect on the prediction. RME is based on so-called \u201ememory profiles\u201d, which are intuitive and can be easily visualised on simple plot charts. Installation RME can be istalled directly from github using pip: pip install git+https://github.com/kobylkam/RME Demo A machine learning model predicting the sentiment of the sentence (whether it is positive or negative) serves as an example of RME demo explanations. Full code of an example can be found in notebooks folder. 1. Creating an explainer At the beginning, we create an explainer and pass the whole dataset to construct a vocabulary. The vocabulary is going to be used to construct perturbations of the instance being explained. from RME import explainer.Explainer e = Explainer(train_set=data) 2. Explaining instance We are interested in explaining the following instance: It is a wonderful World! . We need to pass model's predict_proba function, which outputs classes' probabilities and supply the class we are interested (0 - negative / 1 - positive). e.explain_instance(instance = ['What a wonderful World!'], predict_function = predict_function, class_index=1) We can also calculate step-by-step prediction to see how the prediction changed after each word. e.explain_instance(instance = ['What a wonderful World!'], predict_function = predict_function, class_index=1) 3. Visualization After explaining the instance, the module is ready to visualize obtained results. e.plot_local_perturbations(type='probability_change', title = 'Demo explanation, class: positive') e.plot_local_perturbations(type='probability_change', title = 'Demo explanation, class: positive') e.plot_local_perturbations(type='probability_change', title = 'Demo explanation, class: positive') Once the explainer is constructed, it can serve for various instances. Below, the RME visualizes the impact of the following words on negative sentiment prediction for the sentence: It was the worst and most boring movie I have ever seen . e.explain_instance(instance=['It was the worst movie I have ever seen!'],predict_function=predict_function,class_index=0) e.plot_local_perturbations(type='probability_change', title = 'Demo explanation, class: positive')","title":"Home"},{"location":"#rme-recurrent-memory-explainer","text":"","title":"RME - Recurrent Memory Explainer "},{"location":"#overview","text":"Recurrent Memory Explainer (RME) is a tool for creating interpretable explanations, dedicated to models operating on sequential data. RME focuses on the memory of a sequential model and tries to explain the decision by pointing important places in the sequence that had an effect on the prediction. RME is based on so-called \u201ememory profiles\u201d, which are intuitive and can be easily visualised on simple plot charts.","title":"Overview"},{"location":"#installation","text":"RME can be istalled directly from github using pip: pip install git+https://github.com/kobylkam/RME","title":"Installation"},{"location":"#demo","text":"A machine learning model predicting the sentiment of the sentence (whether it is positive or negative) serves as an example of RME demo explanations. Full code of an example can be found in notebooks folder.","title":"Demo"},{"location":"#1-creating-an-explainer","text":"At the beginning, we create an explainer and pass the whole dataset to construct a vocabulary. The vocabulary is going to be used to construct perturbations of the instance being explained. from RME import explainer.Explainer e = Explainer(train_set=data)","title":"1. Creating an explainer"},{"location":"#2-explaining-instance","text":"We are interested in explaining the following instance: It is a wonderful World! . We need to pass model's predict_proba function, which outputs classes' probabilities and supply the class we are interested (0 - negative / 1 - positive). e.explain_instance(instance = ['What a wonderful World!'], predict_function = predict_function, class_index=1) We can also calculate step-by-step prediction to see how the prediction changed after each word. e.explain_instance(instance = ['What a wonderful World!'], predict_function = predict_function, class_index=1)","title":"2. Explaining instance"},{"location":"#3-visualization","text":"After explaining the instance, the module is ready to visualize obtained results. e.plot_local_perturbations(type='probability_change', title = 'Demo explanation, class: positive') e.plot_local_perturbations(type='probability_change', title = 'Demo explanation, class: positive') e.plot_local_perturbations(type='probability_change', title = 'Demo explanation, class: positive') Once the explainer is constructed, it can serve for various instances. Below, the RME visualizes the impact of the following words on negative sentiment prediction for the sentence: It was the worst and most boring movie I have ever seen . e.explain_instance(instance=['It was the worst movie I have ever seen!'],predict_function=predict_function,class_index=0) e.plot_local_perturbations(type='probability_change', title = 'Demo explanation, class: positive')","title":"3. Visualization"},{"location":"documentation/","text":"RME - documentation Functions","title":"Documentation"},{"location":"documentation/#rme-documentation","text":"","title":"RME - documentation "},{"location":"documentation/#functions","text":"","title":"Functions"}]}